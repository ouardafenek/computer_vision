{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning par extraction de features dans un CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torch.nn as nn \n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pickle, PIL\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/hub.py:463: UserWarning: TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead')\n"
     ]
    }
   ],
   "source": [
    "torchvision.models.vgg.model_urls[\"vgg16\"] = \"http://webia.lip6.fr/~robert/cours/rdfia/vgg16-397923af.pth\"\n",
    "os.environ[\"TORCH_MODEL_ZOO\"] = \"/tmp/torch\"\n",
    "PRINT_INTERVAL = 50\n",
    "CUDA = False\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(batch_size, path):\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.0229,0.224,0.225]\n",
    "    # Cette fonction permet de recopier 3 fois une image qui\n",
    "    # ne serait que sur 1 channel (donc image niveau de gris)\n",
    "    # pour la \"transformer\" en image RGB. Utilisez la avec\n",
    "    # transform.Lambda\n",
    "    def duplicateChannel(img):\n",
    "        img = img.convert('L')\n",
    "        np_img = np.array(img, dtype=np.uint8)\n",
    "        np_img = np.dstack([np_img, np_img, np_img])\n",
    "        img = Image.fromarray(np_img, 'RGB')\n",
    "        return img\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(path+'/train',\n",
    "        transform=transforms.Compose([ # TODO Pré-traitement à faire\n",
    "            transforms.Lambda(lambda img : duplicateChannel(img)),\n",
    "            transforms.Lambda(lambda img : img.resize((224, 224), PIL.Image.BILINEAR)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean,std)\n",
    "        ]))\n",
    "    val_dataset = datasets.ImageFolder(path+'/test',\n",
    "        transform=transforms.Compose([ # TODO Pré-traitement à faire\n",
    "            transforms.Lambda(lambda img : duplicateChannel(img)),\n",
    "            transforms.Lambda(lambda img : img.resize((224, 224), PIL.Image.BILINEAR)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean,std)\n",
    "        ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                        batch_size=batch_size, shuffle=False, pin_memory=CUDA, num_workers=2)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/hub.py:463: UserWarning: TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead')\n"
     ]
    }
   ],
   "source": [
    "import os, torchvision\n",
    "torchvision.models.vgg.model_urls[\"vgg16\"] =\"http://webia.lip6.fr/~robert/cours/rdfia/vgg16-397923af.pth\"\n",
    "os.environ[\"TORCH_HOME\"] = \"/tmp/torch\"\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(data, model):\n",
    "    # TODO init features matrices\n",
    "    X = np.zeros((len(data),data.batch_size,4096)) # 4096 dimension de l'avant derniere couche de VGG16.\n",
    "    y = np.zeros((len(data),data.batch_size))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, target) in enumerate(data):\n",
    "            if i % PRINT_INTERVAL == 0:\n",
    "                print('Batch {0:03d}/{1:03d}'.format(i, len(data)))\n",
    "            if CUDA:\n",
    "                x = x.cuda()\n",
    "            \n",
    "            features = model(x)\n",
    "            X[i] = features.detach().numpy()\n",
    "            y[i]= target.detach().numpy()\n",
    "            \n",
    "            \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reshape_no_batch(X,y):\n",
    "    # Enleve les batch et reshape les données numpy. \n",
    "    X = X.reshape((X.shape[0]*X.shape[1],X.shape[2]))\n",
    "    y = y.reshape((y.shape[0]*y.shape[1]))\n",
    "\n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16relu7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16relu7, self).__init__()\n",
    "        # recopier toute la partie convolutionnelle\n",
    "        self.features = nn.Sequential( *list(vgg16.features.children()))\n",
    "        # garder une partie du classifieur, -2 pour s'arrêter à relu7\n",
    "        self.classifier = nn.Sequential(*list(vgg16.classifier.children())[:-3])\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path = '15SceneData' \n",
    "    batch_size = 4 \n",
    "    \n",
    "    print('Instanciation de VGG16')\n",
    "    vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "    print('Instanciation de VGG16relu7')\n",
    "    model = VGG16relu7() # TODO À remplacer par un reseau tronché pour faire de la feature extraction\n",
    "\n",
    "    model.eval()\n",
    "    if CUDA: # si on fait du GPU, passage en CUDA\n",
    "        model = model.cuda()\n",
    "\n",
    "    # On récupère les données\n",
    "    print('Récupération des données')\n",
    "    train, test = get_dataset(batch_size, path)\n",
    "\n",
    "    \n",
    "    # Extraction des features\n",
    "    print('Feature extraction')\n",
    "    if not os.path.exists('numpy_object/X_train2.npy') : \n",
    "        X_train, y_train = extract_features(train, model)\n",
    "        np.save('numpy_object/X_train2.npy', X_train)\n",
    "        np.save('numpy_object/y_train2.npy', y_train)\n",
    "    else:\n",
    "        print(\"Chargement des fichiers X_train2.npy et y_train2.npy\")\n",
    "        X_train = np.load('numpy_object/X_train2.npy')\n",
    "        y_train = np.load('numpy_object/y_train2.npy')\n",
    "        \n",
    "    if not os.path.exists('numpy_object/X_test2.npy') : \n",
    "        X_test, y_test = extract_features(test, model)\n",
    "        np.save('numpy_object/X_test2.npy', X_test)\n",
    "        np.save('numpy_object/y_test2.npy', y_test)\n",
    "    else:\n",
    "        X_test = np.load('numpy_object/X_test2.npy')\n",
    "        y_test = np.load('numpy_object/y_test2.npy')\n",
    "\n",
    "\n",
    "    X_train,y_train = reshape_no_batch(X_train,y_train)\n",
    "    X_test,y_test = reshape_no_batch(X_test,y_test)\n",
    "\n",
    "    \n",
    "    \n",
    "    print('Apprentissage des SVM')\n",
    "    svm = LinearSVC(C=1.0)\n",
    "    svm.fit(X_train,y_train)\n",
    "    accuracy = svm.score(X_test,y_test)\n",
    "    print(\"SVM accuraccy :\",accuracy)\n",
    "\n",
    "    input(\"done\")\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanciation de VGG16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/hub.py:463: UserWarning: TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instanciation de VGG16relu7\n",
      "Récupération des données\n",
      "Feature extraction\n",
      "Batch 000/375\n",
      "Batch 050/375\n",
      "Batch 100/375\n",
      "Batch 150/375\n",
      "Batch 200/375\n",
      "Batch 250/375\n",
      "Batch 300/375\n",
      "Batch 350/375\n",
      "Batch 000/747\n",
      "Batch 050/747\n",
      "Batch 100/747\n",
      "Batch 150/747\n",
      "Batch 200/747\n",
      "Batch 250/747\n",
      "Batch 300/747\n",
      "Batch 350/747\n",
      "Batch 400/747\n",
      "Batch 450/747\n",
      "Batch 500/747\n",
      "Batch 550/747\n",
      "Batch 600/747\n",
      "Batch 650/747\n",
      "Batch 700/747\n",
      "Apprentissage des SVM\n",
      "SVM accuraccy : 0.7623828647925034\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "CUDA = False \n",
    "X_train, y_train, X_test, y_test = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
